{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f1f9fc-ad62-463c-9497-2d542a0d46cb",
   "metadata": {},
   "source": [
    "# Author: Eoghan O'Connor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7afe0",
   "metadata": {},
   "source": [
    "## Task\n",
    "This jupyterNotebook runs on AWS sageMaker. Needs access to S3 bucket.\n",
    "  <ul>\n",
    "    <li>loads csv data from the AWS S3 storage space and produces an outlier report</li>\n",
    "    <li>gets hystory rates from the marketplace CryptoCompare.com and produces an outlier report</li>\n",
    "    <li>Get live-exchange cryptocurrency rates from the marketplace CryptoCompare.com on every 30 sec </li>\n",
    "        <li>Store these cryptocurrency rates.</li>\n",
    "    <li>Detect outliers among these cryptocurrency rates.</li>\n",
    "  </ul>\n",
    "  <br>\n",
    "The following unsupervised learning methods are used for outlier detection\n",
    "<ul><li>Enhanced Dixon Q</li>\n",
    "<li>Mean & Standard Deviation</li>\n",
    "<li>Isolation Forest</li>\n",
    "<li>Boxplots Method</li>\n",
    "<li>DBSCAN Clustering Method</li>\n",
    "</ul></li>  </ul>  \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c491d2",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee33d5",
   "metadata": {},
   "source": [
    "### Libraries to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f88182",
   "metadata": {},
   "source": [
    "#### Method #1: Dixon Q Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934df987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\"\"\"\n",
    " *\n",
    " * This class implements an enhanced version of DixonQ Test.\n",
    " * Provides a set of encoded critical values - up to 100.\n",
    " * The encoded critical values are used as a basis to generate critical values for other alphas (levels of confidence).\n",
    " * Both encoded and generated critical values are used to produce a result of maximum accuracy when identifying outliers. \n",
    " *  \n",
    "\"\"\" \n",
    "class DixonQEnhanced:\n",
    "    \n",
    "    criticalValues = {}\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * DixonQEnhanced constructor\n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        self.buildCriticalValues()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Builds a dictionary of critical values grouped by alpha  \n",
    "    \"\"\"\n",
    "    def buildCriticalValues(self):\n",
    "        \n",
    "        \"\"\"\n",
    "         * the critical values are grouped by an alpha key\n",
    "         * alpha is the probability of incorrectly rejecting the suspected outlier\n",
    "        \"\"\"    \n",
    "        #encoded critical values for alpha = 0.3 (0.7% level of confidence)\n",
    "        self.criticalValues[0.30] = [0,0,\n",
    "                                     0.6836,0.4704,0.3730,0.3173,0.2811,0.2550,0.2361,0.2208,\n",
    "                                     0.2086,0.1983,0.1898,0.1826,0.1764,0.1707,0.1656,0.1613,\n",
    "                                     0.1572,0.1535,0.1504,0.1474,0.1446,0.1420,0.1397,0.1376,\n",
    "                                     0.1355,0.1335,0.1318,0.1300,0.1283,0.1268,0.1255,0.1240,\n",
    "                                     0.1227,0.1215,0.1202,0.1192,0.1181,0.1169,0.1160,0.1153,\n",
    "                                     0.1141,0.1134,0.1124,0.1116,0.1108,0.1102,0.1093,0.1087,\n",
    "                                     0.1079,0.1071,0.1067,0.1060,0.1052,0.1047,0.1041,0.1036,\n",
    "                                     0.1030,0.1024,0.1019,0.1014,0.1009,0.1004,0.1000,0.0997,\n",
    "                                     0.0991,0.0987,0.0982,0.0979,0.0974,0.0970,0.0967,0.0961,\n",
    "                                     0.0960,0.0955,0.0952,0.0948,0.0943,0.0939,0.0937,0.0935,\n",
    "                                     0.0930,0.0928,0.0925,0.0921,0.0918,0.0915,0.0913,0.0910,\n",
    "                                     0.0906,0.0903,0.0902,0.0899,0.0896,0.0894,0.0892,0.0890,\n",
    "                                     0.0887,0.0885]\n",
    "        \n",
    "        #encoded critical values for alpha = 0.2 (0.8% level of confidence)\n",
    "        self.criticalValues[0.20] = [0,0,\n",
    "                                     0.7808,0.5603,0.4508,0.3868,0.3444,0.3138,0.2915,0.2735,\n",
    "                                     0.2586,0.2467,0.2366,0.2280,0.2202,0.2137,0.2077,0.2023,\n",
    "                                     0.1973,0.1929,0.1890,0.1854,0.1820,0.1790,0.1761,0.1735,\n",
    "                                     0.1710,0.1687,0.1664,0.1645,0.1624,0.1604,0.1590,0.1571,\n",
    "                                     0.1555,0.1540,0.1525,0.1512,0.1499,0.1484,0.1472,0.1462,\n",
    "                                     0.1449,0.1441,0.1430,0.1418,0.1408,0.1400,0.1390,0.1381,\n",
    "                                     0.1374,0.1365,0.1357,0.1349,0.1340,0.1334,0.1326,0.1320,\n",
    "                                     0.1312,0.1304,0.1299,0.1294,0.1286,0.1281,0.1275,0.1272,\n",
    "                                     0.1264,0.1260,0.1254,0.1249,0.1243,0.1238,0.1234,0.1228,\n",
    "                                     0.1225,0.1221,0.1217,0.1212,0.1205,0.1201,0.1198,0.1195,\n",
    "                                     0.1189,0.1187,0.1182,0.1178,0.1174,0.1171,0.1167,0.1165,\n",
    "                                     0.1160,0.1156,0.1154,0.1151,0.1147,0.1144,0.1141,0.1138,\n",
    "                                     0.1134,0.1131]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.1 (0.9% level of confidence)\n",
    "        self.criticalValues[0.10] = [0,0,\n",
    "                                     0.8850,0.6789,0.5578,0.4840,0.4340,0.3979,0.3704,0.3492,\n",
    "                                     0.3312,0.3170,0.3045,0.2938,0.2848,0.2765,0.2691,0.2626,\n",
    "                                     0.2564,0.2511,0.2460,0.2415,0.2377,0.2337,0.2303,0.2269,\n",
    "                                     0.2237,0.2208,0.2182,0.2155,0.2132,0.2110,0.2088,0.2066,\n",
    "                                     0.2045,0.2026,0.2008,0.1993,0.1974,0.1958,0.1944,0.1930,\n",
    "                                     0.1915,0.1902,0.1890,0.1875,0.1865,0.1850,0.1839,0.1829,\n",
    "                                     0.1819,0.1808,0.1797,0.1788,0.1777,0.1768,0.1759,0.1752,\n",
    "                                     0.1741,0.1733,0.1726,0.1717,0.1707,0.1703,0.1694,0.1689,\n",
    "                                     0.1679,0.1674,0.1667,0.1660,0.1652,0.1648,0.1641,0.1635,\n",
    "                                     0.1631,0.1626,0.1620,0.1613,0.1605,0.1601,0.1596,0.1594,\n",
    "                                     0.1586,0.1583,0.1576,0.1573,0.1567,0.1563,0.1557,0.1554,\n",
    "                                     0.1547,0.1544,0.1540,0.1537,0.1532,0.1528,0.1524,0.1521,\n",
    "                                     0.1516,0.1512]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.05 (0.95% level of confidence)\n",
    "        self.criticalValues[0.05] = [0,0,\n",
    "                                     0.9411,0.7651,0.6423,0.5624,0.5077,0.4673,0.4363,0.4122,\n",
    "                                     0.3922,0.3755,0.3615,0.3496,0.3389,0.3293,0.3208,0.3135,\n",
    "                                     0.3068,0.3005,0.2947,0.2895,0.2851,0.2804,0.2763,0.2725,\n",
    "                                     0.2686,0.2655,0.2622,0.2594,0.2567,0.2541,0.2513,0.2488,\n",
    "                                     0.2467,0.2445,0.2423,0.2408,0.2383,0.2366,0.2350,0.2334,\n",
    "                                     0.2319,0.2302,0.2288,0.2273,0.2257,0.2241,0.2228,0.2216,\n",
    "                                     0.2206,0.2191,0.2182,0.2169,0.2160,0.2145,0.2135,0.2126,\n",
    "                                     0.2116,0.2106,0.2095,0.2085,0.2075,0.2070,0.2057,0.2053,\n",
    "                                     0.2045,0.2037,0.2030,0.2020,0.2013,0.2005,0.1996,0.1990,\n",
    "                                     0.1984,0.1980,0.1973,0.1964,0.1955,0.1950,0.1943,0.1940,\n",
    "                                     0.1934,0.1927,0.1922,0.1918,0.1909,0.1906,0.1899,0.1896,\n",
    "                                     0.1887,0.1885,0.1881,0.1876,0.1869,0.1865,0.1860,0.1856,\n",
    "                                     0.1851,0.1846]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.02 (0.98% level of confidence)\n",
    "        self.criticalValues[0.02] = [0,0,\n",
    "                                     0.9763,0.8457,0.7291,0.6458,0.5864,0.5432,0.5091,0.4813,\n",
    "                                     0.4591,0.4405,0.4250,0.4118,0.3991,0.3883,0.3792,0.3711,\n",
    "                                     0.3630,0.3562,0.3495,0.3439,0.3384,0.3328,0.3287,0.3242,\n",
    "                                     0.3202,0.3163,0.3127,0.3093,0.3060,0.3036,0.2999,0.2973,\n",
    "                                     0.2948,0.2921,0.2898,0.2879,0.2853,0.2836,0.2815,0.2794,\n",
    "                                     0.2778,0.2758,0.2744,0.2726,0.2711,0.2690,0.2676,0.2662,\n",
    "                                     0.2651,0.2632,0.2620,0.2606,0.2595,0.2582,0.2570,0.2555,\n",
    "                                     0.2545,0.2531,0.2522,0.2510,0.2500,0.2493,0.2480,0.2472,\n",
    "                                     0.2466,0.2457,0.2445,0.2436,0.2429,0.2420,0.2409,0.2402,\n",
    "                                     0.2398,0.2387,0.2382,0.2372,0.2365,0.2360,0.2349,0.2345,\n",
    "                                     0.2337,0.2330,0.2322,0.2319,0.2309,0.2304,0.2298,0.2294,\n",
    "                                     0.2285,0.2279,0.2272,0.2272,0.2259,0.2257,0.2251,0.2247,\n",
    "                                     0.2240,0.2234]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.01 (0.99% level of confidence)\n",
    "        self.criticalValues[0.01] = [0,0,\n",
    "                                     0.9881,0.8886,0.7819,0.6987,0.6371,0.5914,0.5554,0.5260,\n",
    "                                     0.5028,0.4831,0.4664,0.4517,0.4385,0.4268,0.4166,0.4081,\n",
    "                                     0.4002,0.3922,0.3854,0.3789,0.3740,0.3674,0.3625,0.3583,\n",
    "                                     0.3543,0.3499,0.3460,0.3425,0.3390,0.3357,0.3323,0.3294,\n",
    "                                     0.3266,0.3238,0.3213,0.3187,0.3163,0.3141,0.3124,0.3102,\n",
    "                                     0.3081,0.3061,0.3050,0.3028,0.3009,0.2991,0.2972,0.2960,\n",
    "                                     0.2941,0.2927,0.2920,0.2899,0.2880,0.2873,0.2859,0.2845,\n",
    "                                     0.2828,0.2816,0.2812,0.2792,0.2784,0.2775,0.2766,0.2754,\n",
    "                                     0.2742,0.2735,0.2724,0.2714,0.2709,0.2696,0.2682,0.2677,\n",
    "                                     0.2667,0.2662,0.2656,0.2646,0.2637,0.2633,0.2621,0.2614,\n",
    "                                     0.2608,0.2599,0.2588,0.2584,0.2573,0.2568,0.2566,0.2558,\n",
    "                                     0.2548,0.2543,0.2539,0.2535,0.2524,0.2521,0.2512,0.2513,\n",
    "                                     0.2499,0.2498]   \n",
    "        \n",
    "        #encoded critical values for alpha = 0.005 (0.995% level of confidence)\n",
    "        self.criticalValues[0.005] = [0,0,\n",
    "                                     0.9940,0.9201,0.8234,0.7437,0.6809,0.6336,0.5952,0.5668,\n",
    "                                     0.5416,0.5208,0.5034,0.4869,0.4739,0.4614,0.4504,0.4423,\n",
    "                                     0.4333,0.4247,0.4173,0.4109,0.4051,0.3986,0.3935,0.3889,\n",
    "                                     0.3843,0.3801,0.3762,0.3718,0.3685,0.3646,0.3610,0.3583,\n",
    "                                     0.3548,0.3522,0.3498,0.3465,0.3443,0.3415,0.3400,0.3377,\n",
    "                                     0.3353,0.3332,0.3325,0.3298,0.3279,0.3256,0.3235,0.3225,\n",
    "                                     0.3204,0.3191,0.3177,0.3163,0.3140,0.3136,0.3118,0.3098,\n",
    "                                     0.3089,0.3075,0.3071,0.3061,0.3041,0.3031,0.3025,0.3006,\n",
    "                                     0.2996,0.2990,0.2983,0.2968,0.2959,0.2946,0.2934,0.2932,\n",
    "                                     0.2922,0.2912,0.2905,0.2897,0.2885,0.2876,0.2870,0.2859,\n",
    "                                     0.2852,0.2844,0.2836,0.2832,0.2818,0.2811,0.2808,0.2798,\n",
    "                                     0.2790,0.2788,0.2784,0.2775,0.2766,0.2764,0.2755,0.2751,\n",
    "                                     0.2738,0.2737]   \n",
    "\n",
    "        \"\"\"\n",
    "         * Generates all critical values by using the encoded values as a basis.\n",
    "         * Values are genereated between any two existing pairs of alphas.\n",
    "        \"\"\" \n",
    "        #generate range alpha 0.2 - 0.1\n",
    "        self.generateCriticalValuesForAlphaPair(0.2,0.1)\n",
    "\n",
    "        #generate range alpha 0.3 - 0.2\n",
    "        self.generateCriticalValuesForAlphaPair(0.3,0.2)\n",
    "\n",
    "        #generate range alpha 0.10 - 0.05\n",
    "        self.generateCriticalValuesForAlphaPair(0.10,0.05)\n",
    "\n",
    "        #generate range alpha 0.05 - 0.02\n",
    "        self.generateCriticalValuesForAlphaPair(0.05,0.02)\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "     * Generates the missing series of critical values between two alphas with a step = 0.01\n",
    "     * constraint: alpha1 > alpha2\n",
    "    \"\"\" \n",
    "    def generateCriticalValuesForAlphaPair(self, alpha1, alpha2):\n",
    "        \n",
    "        if alpha1 < alpha2:\n",
    "            raise Exception('The value of alpha1 is less than alpha2.')\n",
    "            \n",
    "        nInsideAlphas = int(round((alpha1 - alpha2)/(0.01)) - 1)\n",
    "        \n",
    "        insideAlphas = []\n",
    "        \n",
    "        step = 0.01\n",
    "        for i in range(1,nInsideAlphas+1):\n",
    "            newAlpha = round(alpha2 + i*step,2)\n",
    "            insideAlphas.append(newAlpha) \n",
    "        \n",
    "        for index in range(2,100):\n",
    "\n",
    "            rangeLeft = self.criticalValues[alpha1][index]\n",
    "            rangeRight = self.criticalValues[alpha2][index]\n",
    "        \n",
    "            distance = round(((rangeRight - rangeLeft)/(nInsideAlphas+1)),4)\n",
    "            \n",
    "            currentValue = self.criticalValues[alpha1][index]\n",
    "            \n",
    "            for insideAlpha in insideAlphas:\n",
    "                \n",
    "                if insideAlpha not in self.criticalValues.keys():\n",
    "                    self.criticalValues[insideAlpha] = []\n",
    "                    self.criticalValues[insideAlpha].append(0)\n",
    "                    self.criticalValues[insideAlpha].append(0)\n",
    "                \n",
    "                currentValue += distance\n",
    "                \n",
    "                currentValue = round(currentValue,4)\n",
    "                \n",
    "                self.criticalValues[insideAlpha].append(currentValue)      \n",
    "                \n",
    "    \"\"\"\n",
    "     * Finds the next element in a series of elements\n",
    "    \"\"\"\n",
    "    def findNextInSeries(self, number, series):\n",
    "        \n",
    "        result = -1\n",
    "        \n",
    "        try:\n",
    "            index = np.abs(series.values - number).argmin()\n",
    "        except ValueError as e:\n",
    "            raise Exception('The number has not been found in the series.')\n",
    "\n",
    "        if index == (len(series) - 1):\n",
    "            result = index - 1\n",
    "        else:\n",
    "            result = index + 1\n",
    "\n",
    "        return result\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Finds the previous element in a series of elements\n",
    "    \"\"\"\n",
    "    def findPreviousInSeries(self, number, series):\n",
    "        \n",
    "        result = -1\n",
    "        \n",
    "        try:\n",
    "            index = np.abs(series.values - number).argmin()\n",
    "        except ValueError as e:\n",
    "            raise Exception('The number has not been found in the series.')\n",
    "\n",
    "        if index == 0:\n",
    "            result = index + 1\n",
    "        else:\n",
    "            result = index - 1\n",
    "\n",
    "        return result\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Identifies if a number is outlier within a series and for particular alpha\n",
    "    \"\"\"\n",
    "    def isOutlier(self, number, series, alpha):\n",
    "                \n",
    "        qCritical = 0.0\n",
    "        \n",
    "        qExpDivisor = series[len(series)-1] - series[0]\n",
    "        \n",
    "        if qExpDivisor == 0:\n",
    "            return False\n",
    "        \n",
    "        if len(series) > 100:\n",
    "            return False\n",
    "\n",
    "        nextNumberGap = abs(number - series[self.findNextInSeries(number,series)])\n",
    "        prevNumberGap = abs(number - series[self.findPreviousInSeries(number,series)])\n",
    "        if prevNumberGap < nextNumberGap:\n",
    "            closestNumberGap = prevNumberGap\n",
    "        else:\n",
    "            closestNumberGap = nextNumberGap\n",
    "            \n",
    "        qExp = closestNumberGap/qExpDivisor\n",
    "        \n",
    "        if alpha in self.criticalValues.keys():\n",
    "            qCritical = self.criticalValues[alpha][len(series)-1]\n",
    "            \n",
    "        if qExp > qCritical:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "     * Identifies all the outliers within a series\n",
    "     * Uses the isOutlier method\n",
    "    \"\"\"\n",
    "    def findOutliers(self, series):\n",
    "        \n",
    "        outliers = {}\n",
    "        \n",
    "        for alpha in self.criticalValues.keys():            \n",
    "            for number in series:\n",
    "                if self.isOutlier(number,series,alpha):\n",
    "                    if number in outliers:\n",
    "                        if outliers[number] < (1-alpha):\n",
    "                            outliers[number] = (1-alpha)\n",
    "                    else:\n",
    "                        outliers[number] = (1-alpha)\n",
    "                        \n",
    "        return outliers\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "     * Checks if the data set is normally distributed;\n",
    "     * running DixonQ Test on different distributions will lead to erroneous results\n",
    "     *\n",
    "     * Runs a Shapiro-Wilk test to check if the series is Gaussian\n",
    "    \"\"\"    \n",
    "    def checkForNormalDisribution(self, series):\n",
    "        \n",
    "        print(\"Shapiro-Wilk: Running Shapiro-Wilk test ....\")\n",
    "        \n",
    "        stat, p = shapiro(series)\n",
    "        \n",
    "        alpha = 0.05\n",
    "        \n",
    "        if p > alpha:       \n",
    "            print(\"Shapiro-Wilk: Series looks Gaussian\")\n",
    "            print(\"\")\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            print(\"Shapiro-Wilk: Series does not look Gaussian\")\n",
    "            print(\"\")\n",
    "            return False\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "     * Executes DixonQ Test on the provided series of numbers;\n",
    "     * DixonQ Test is executed for all available alpha keys (levels of confidence)\n",
    "    \"\"\" \n",
    "    def execute(self, series):\n",
    "        \n",
    "        outliers = {}\n",
    "\n",
    "        series.sort(reverse=False)\n",
    "        \n",
    "        if not self.checkForNormalDisribution(series):\n",
    "            print(\"DixonQ Test: Warning: Test should not be run on a series that is not normally distributed.\")\n",
    "\n",
    "        outliers = self.findOutliers(series)\n",
    "        \n",
    "        return outliers        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478d462",
   "metadata": {},
   "source": [
    "#### Method #2: Mean & Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8430b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Standard Deviation Method for detecting outliers\n",
    "\"\"\"\n",
    "class StandardDeviationMethod:\n",
    "    \n",
    "    \n",
    "    methodName = \"StandardDeviationMethod\"\n",
    "    \n",
    "    upperLimit = 0.0\n",
    "    lowerLimit = 0.0\n",
    "    seriesStd = 0.0\n",
    "    seriesMean = 0.0\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def getMethodName(self):\n",
    "        return \"Standard Deviation Method\"\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        \n",
    "        outliers = []\n",
    "    \n",
    "        # set upper and lower limits to 3 times the standard deviation\n",
    "        seriesStd = np.std(series)\n",
    "        seriesMean = np.mean(series)\n",
    "        #anomalyCutOff = seriesStd * 3\n",
    "        #anomalyCutOff = seriesStd * 2\n",
    "        #anomalyCutOff = seriesStd * 1.5\n",
    "        #anomalyCutOff = seriesStd * 1.75\n",
    "        anomalyCutOff = seriesStd * 2.5\n",
    "        \n",
    "        lowerLimit  = seriesMean - anomalyCutOff \n",
    "        upperLimit = seriesMean + anomalyCutOff\n",
    "        \n",
    "        #print(lowerLimit)\n",
    "        \n",
    "        self.upperLimit = upperLimit\n",
    "        self.lowerLimit = lowerLimit\n",
    "        self.seriesStd = seriesStd\n",
    "        self.seriesMean = seriesMean\n",
    "\n",
    "        # generate outliers\n",
    "        for outlier in series:\n",
    "            if outlier > upperLimit or outlier < lowerLimit:\n",
    "                outliers.append(outlier)\n",
    "                \n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0ad53",
   "metadata": {},
   "source": [
    "#### Method #3: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9ced15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Isolation Forest Method for detecting outliers\n",
    "\"\"\"\n",
    "class IsolationForestMethod:\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def __init__(self):       \n",
    "        pass\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def checkAllElementsEqual(self, series):\n",
    "        return len(set(series)) <= 1\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        outliers = []\n",
    "        \n",
    "        if not self.checkAllElementsEqual(series):          \n",
    "            df = pd.DataFrame({'temp':series})\n",
    "            clf = IsolationForest().fit(df['temp'].values.reshape(-1, 1)) \n",
    "            outliersInds = clf.predict(df['temp'].values.reshape(-1, 1))\n",
    "            \n",
    "            for indx in range(0, len(outliersInds)):\n",
    "                if outliersInds[indx] == -1:\n",
    "                    outliers.append(series.iloc[indx])  # Change this line\n",
    "                    \n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a983fcf",
   "metadata": {},
   "source": [
    "#### Method #4: Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21e4840c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Boxplots Method for detecting outliers\n",
    "\"\"\"\n",
    "class BoxPlotsMethod:\n",
    "        \n",
    "    methodName = \"BoxPlotsMethod\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def getMethodName(self):\n",
    "        return \"Boxplots Method\"\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        outliers = []\n",
    "\n",
    "        ax = sns.boxplot(data=series, whis=0)\n",
    "        \n",
    "        outliers = [y for stat in boxplot_stats(series) for y in stat['fliers']]\n",
    "\n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4b5e6",
   "metadata": {},
   "source": [
    "#### Method #5:  DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5fcb0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the DBScan Clustering Method for detecting outliers\n",
    "\"\"\"\n",
    "class DBScanClusteringMethod:\n",
    "\n",
    "    \n",
    "    methodName = \"DBScanClusteringMethod\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def checkAllElementsEqual(self, series):\n",
    "        return len(set(series)) <= 1\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def getMethodName(self):\n",
    "        return \"DBScan Clustering Method\"\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        outliers = []\n",
    "\n",
    "        if not self.checkAllElementsEqual(series):\n",
    "            \n",
    "            df = pd.DataFrame({'temp':series})\n",
    "            outliersDetection = DBSCAN(min_samples = 5, eps = 0.5)\n",
    "            outliersInds = outliersDetection.fit_predict(df['temp'].values.reshape(-1, 1))\n",
    "            \n",
    "            for indx in range(0, len(outliersInds)):\n",
    "\n",
    "                if outliersInds[indx] == -1:\n",
    "                    outliers.append(series[indx])    \n",
    "\n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953cc19",
   "metadata": {},
   "source": [
    "#### CryptoCompare Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181714f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "CryptoCompare.com Reader class - uses CryptoCompare.com API to retrieve history data\n",
    "\"\"\"\n",
    "class CryptoCompareReader:\n",
    "    \n",
    "    apiKey = \"fe6382d7770ad0c939c5c12d51e76ab772afbc361f2900405fe8bc930e31ed97\"\n",
    "    urlCurrent = \"https://min-api.cryptocompare.com/data/pricemulti?fsyms=$1&tsyms=USD&api_key=\" + apiKey\n",
    "    urlHistory = \"https://min-api.cryptocompare.com/data/v2/histoday?fsym=$1&tsym=USD&limit=$2\"\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    \n",
    "    def extractCoinRates(self, apiResult):\n",
    "        usdToCoinRates = []\n",
    "        \n",
    "        data = apiResult.get(\"Data\").get(\"Data\")\n",
    "        \n",
    "        for cryptoCurrency in data:\n",
    "            coinResult = cryptoCurrency[\"close\"]\n",
    "            usdToCoinRates.append(coinResult)\n",
    "\n",
    "        return usdToCoinRates\n",
    "\n",
    "    \n",
    "    def readHistoryRates (self, cryptoCurrency, size):\n",
    "        \n",
    "        urlRestAPI = self.urlHistory.replace(\"$1\", cryptoCurrency)\n",
    "\n",
    "        urlRestAPI = urlRestAPI.replace(\"$2\", size)\n",
    "        \n",
    "        response = requests.get(urlRestAPI)\n",
    "        \n",
    "        return self.extractCoinRates(response.json())\n",
    "    \n",
    "    \n",
    "    def readCurrentRate (self, cryptoCurrency):\n",
    "        \n",
    "        urlRestAPI = self.urlCurrent.replace(\"$1\", cryptoCurrency)\n",
    "\n",
    "        response = requests.get(urlRestAPI).json()\n",
    "        \n",
    "        coinRate = response[cryptoCurrency].get('USD')\n",
    "        \n",
    "        return coinRate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef77d901",
   "metadata": {},
   "source": [
    "#### AWS S3 Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97486657",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Your Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4191de72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib2to3.pgen2.pgen import DFAState\n",
    "import numpy as np\n",
    "import boto3\n",
    "import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\"\"\"\n",
    " * This class provides utility functions to interact with S3\n",
    "\"\"\"\n",
    "class S3Utils:\n",
    "    \n",
    "    \n",
    "    methodName = \"S3Utils\"\n",
    "\n",
    "    \"\"\"\n",
    "     Utility class for bucket ops\n",
    "    \"\"\" \n",
    "    def __init__(self, bucket_name : str):\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    def _delete_file_(self, file_name: str):\n",
    "        s3.delete_object(\n",
    "            Key=file_name,\n",
    "            Bucket=self.bucket_name,\n",
    "        )\n",
    "\n",
    "    def _upload_file_(self, file_name: str):\n",
    "        file_size = os.stat(file_name).st_size\n",
    "        with tqdm.tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=file_name) as pbar:\n",
    "            s3.upload_file(\n",
    "                Filename=file_name,\n",
    "                Bucket=self.bucket_name,\n",
    "                Key=file_name,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred),\n",
    "            )\n",
    "\n",
    "    def _download_file_(self, file_name: str):\n",
    "        print(f\"The file name is {'data/'+ file_name} the bucket is {self.bucket_name}\")\n",
    "        object_size = s3.head_object(**{\"Bucket\": self.bucket_name, \"Key\": file_name})[\"ContentLength\"]\n",
    "        with tqdm.tqdm(total=object_size, unit=\"B\", unit_scale=True, desc=file_name) as pbar:\n",
    "            s3.download_file(\n",
    "                Bucket=self.bucket_name,\n",
    "                Key=file_name,\n",
    "                Filename='./data/'+ file_name,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred),\n",
    "            )\n",
    "\n",
    "    \"\"\"\n",
    "     Uploads a file to the bucket\n",
    "    \"\"\"\n",
    "    def addFileToBucket(self, file_name: str):\n",
    "        self._upload_file_(file_name)\n",
    "\n",
    "    \"\"\"\n",
    "     Appends one row to the csv file in bucket\n",
    "    \"\"\"\n",
    "    def writeRowToCsvFileInBucket(self, file_name: str, values: list):\n",
    "        # If not exists in data folder download\n",
    "        if not os.path.exists('./data/' + file_name):\n",
    "            self._download_file_(file_name)\n",
    "        # convert to a dataframe and return to caller\n",
    "        df = pd.read_csv('./data/' + file_name)\n",
    "        df_new_line = pd.DataFrame([values], columns=df.columns)\n",
    "        df_new_line.to_csv(file_name, mode='a', index=False, header=False)\n",
    "        self._delete_file_(file_name)\n",
    "        self._upload_file_(file_name)\n",
    "\n",
    "    \"\"\"\n",
    "     Gets a csv file from bucket and returns a dataframe\n",
    "    \"\"\"\n",
    "    def readCsvFileFromBucket(self, file_name: str) -> pd.DataFrame:\n",
    "        if os.path.exists('./data/' + file_name):\n",
    "            os.remove('./data/' + file_name)\n",
    "        self._download_file_(file_name)\n",
    "        return pd.read_csv('./data/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3df4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import botocore\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "class bucket_class:\n",
    "    def __init__(self, bucket_name: str):\n",
    "        self.s3_utils = S3Utils(bucket_name)\n",
    "        self.bucket_name = bucket_name\n",
    "        self.client = boto3.client('s3')\n",
    "        session = boto3.Session(region_name='us-west-2')\n",
    "        self.s3 = session.resource('s3')\n",
    "        self.bucket = self.s3.Bucket(bucket_name)\n",
    "        self.bucket.put_object(Key='results/', Body='')\n",
    "\n",
    "    def saveCsvToBucket(self, data, fileName):\n",
    "        try:\n",
    "            # Save to s3 bucket\n",
    "            csv_path = 'results/'+ fileName\n",
    "            csv_buffer = io.StringIO()\n",
    "            data.to_csv(csv_buffer, index=False)\n",
    "            self.bucket.put_object(Key=csv_path, Body=csv_buffer.getvalue())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "\n",
    "    # describes a series and saves the result to a file\n",
    "    def describeSeries(self, series, fileName):\n",
    "        desc = series.describe()\n",
    "        desc_df = pd.DataFrame(desc)\n",
    "        try:\n",
    "            desc_df.to_csv(fileName)\n",
    "        except:\n",
    "            return False\n",
    "        data = pd.read_csv(fileName)\n",
    "        self.saveCsvToBucket(data, fileName)\n",
    "\n",
    "    def extractSeriesFromDF(self, df: pd.DataFrame, crypto_currency: str) -> pd.Series:\n",
    "        df_filtered = df[(df['instrument_ticker'] == crypto_currency) & (df['currency_code'] == 'USD')]\n",
    "        return df_filtered['offer']\n",
    "\n",
    "    def extractSeriesFromCryptoCompare(self, crypto_currency: str) -> pd.Series:\n",
    "        crypto_compare_reader = CryptoCompareReader()\n",
    "        return pd.Series(crypto_compare_reader.readHistoryRates(crypto_currency, '600'))\n",
    "\n",
    "    def extract100ElementsAtRandom(self, series: pd.Series) -> pd.Series:\n",
    "        if len(series) > 100:\n",
    "            return series.sample(n=100).reset_index(drop=True)\n",
    "        return series\n",
    "\n",
    "    def executeDixonQ(self, series: pd.Series):\n",
    "        dixon_q = DixonQEnhanced()\n",
    "        # sorted_series = series.sort_values().reset_index(drop=True)\n",
    "        outliers = dixon_q.findOutliers(series)\n",
    "        return outliers\n",
    "\n",
    "    def executeStDeviation(self, series: pd.Series):\n",
    "        stdev_detector = StandardDeviationMethod()\n",
    "        sorted_series = series.sort_values().reset_index(drop=True)\n",
    "        outliers = stdev_detector.execute(sorted_series)\n",
    "        return outliers\n",
    "\n",
    "    def executeIsolationForest(self, series: pd.Series):\n",
    "        iforest = IsolationForestMethod()\n",
    "        sorted_series = series.sort_values().reset_index(drop=True)\n",
    "        outliers = iforest.execute(sorted_series)\n",
    "        return outliers\n",
    "\n",
    "    def executeBoxPlots(self, series: pd.Series):\n",
    "        boxplots = BoxPlotsMethod()\n",
    "        sorted_series = series.sort_values().reset_index(drop=True)\n",
    "        outliers = boxplots.execute(sorted_series)\n",
    "        return outliers\n",
    "\n",
    "    def executeDBSCAN(self, series: pd.Series):\n",
    "        dbscan = DBScanClusteringMethod()\n",
    "        sorted_series = series.sort_values().reset_index(drop=True)\n",
    "        outliers = dbscan.execute(sorted_series)\n",
    "        return outliers\n",
    "\n",
    "    def produceJsonOutliers(self, json_file_name, series_100, \n",
    "                            outliers_DQ, outliers_StD, outliers_IF,\n",
    "                            outliers_BXPLT, outliers_DBSCN):\n",
    "\n",
    "        joint_outliers, Joint_Outliers_DQ_StD, Joint_Outliers_DQ_IF, Joint_Outliers_StD_IF = self.produceJointResultOutOfAll(outliers_DQ, outliers_StD, outliers_IF, outliers_BXPLT, outliers_DBSCN)\n",
    "        # Create the JSON data\n",
    "        data = {\n",
    "            \"series\": series_100.tolist(),\n",
    "            \"outliers\": {\n",
    "                \"joint_outliers\": joint_outliers,\n",
    "                \"DixonQ\": outliers_DQ,\n",
    "                \"StandardDeviation\": outliers_StD,\n",
    "                \"IsolationForest\": outliers_IF,\n",
    "                \"Boxplot\": outliers_BXPLT,\n",
    "                \"DBSCAN\": outliers_DBSCN,\n",
    "                \"Joint_Outliers_DQ_StD\": Joint_Outliers_DQ_StD,\n",
    "                \"Joint_Outliers_DQ_IF\": Joint_Outliers_DQ_IF,\n",
    "                \"Joint_Outliers_StD_IF\": Joint_Outliers_StD_IF\n",
    "            }\n",
    "        }\n",
    "        print(data)\n",
    "        json_string = json.dumps(data)\n",
    "        # Upload the JSON file to S3\n",
    "        try:\n",
    "            self.bucket.put_object(Key='results/'+json_file_name, Body=json_string)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "    def produceJointResultOutOfAll(self, outliers_DQ, outliers_StD, outliers_IF, outliers_BXPLT, outliers_DBSCN):\n",
    "        joint_outliers = []\n",
    "\n",
    "        all_outliers = outliers_DQ + outliers_StD + outliers_IF + outliers_BXPLT + outliers_DBSCN\n",
    "        # Count the number of times each outlier occurs\n",
    "        outlier_counts = {}\n",
    "        for outlier in all_outliers:\n",
    "            if outlier not in outlier_counts:\n",
    "                outlier_counts[outlier] = 1\n",
    "            else:\n",
    "                outlier_counts[outlier] += 1\n",
    "\n",
    "        Joint_Outliers_DQ_StD = list(set(outliers_DQ) & set(outliers_StD))\n",
    "        Joint_Outliers_DQ_IF = list(set(outliers_DQ) & set(outliers_IF))\n",
    "        Joint_Outliers_StD_IF = list(set(outliers_StD) & set(outliers_IF))\n",
    "        # Majority voting i.e. 3 or more outlier detectors agree.\n",
    "        joint_outliers = [outlier for outlier, count in outlier_counts.items() if count >= 3]\n",
    "        return joint_outliers, Joint_Outliers_DQ_StD, Joint_Outliers_DQ_IF, Joint_Outliers_StD_IF\n",
    "\n",
    "\n",
    "    def executePhase(self, phase, series):\n",
    "        print(\"in \"+ phase)\n",
    "        # step #1: exit on series size < 3\n",
    "        if len(series) < 3:\n",
    "            return False\n",
    "        # step #2: if series size > 100 then create a series of 100 elements\n",
    "        # selected at random from series\n",
    "        if len(series) >= 100:\n",
    "            print(\"Getting sample that has outliers for all methods\")\n",
    "            series_100 = self.extract100ElementsAtRandom(series)\n",
    "\n",
    "            dixon_outliers = list(self.executeDixonQ(series_100))\n",
    "            stdev_outliers = list(self.executeStDeviation(series_100))\n",
    "            isolation_outliers = list(self.executeIsolationForest(series_100))\n",
    "            boxplot_outliers = list(self.executeBoxPlots(series_100))\n",
    "            DBSCAN_outliers = list(self.executeDBSCAN(series_100))\n",
    "\n",
    "            folder = 'results/'\n",
    "            fileName = 'describe_series_' + phase + '.csv'\n",
    "            fileName100 = 'describe_series100_' + phase + '.csv'\n",
    "            json_file_name = 'outlier_results_' + phase + '.json'\n",
    "\n",
    "            self.produceJsonOutliers(json_file_name, series_100, dixon_outliers,\n",
    "                                     stdev_outliers, isolation_outliers, \n",
    "                                     boxplot_outliers, DBSCAN_outliers)\n",
    "            self.describeSeries(series, fileName)\n",
    "            self.describeSeries(series_100, fileName100)\n",
    "        return True\n",
    "\n",
    "    def execute(self, s3_file_key: str, crypto_currency: str):\n",
    "        # # phase 1\n",
    "        s3_df = pd.read_csv('data/' + s3_file_key)\n",
    "        series = self.extractSeriesFromDF(s3_df, crypto_currency)\n",
    "        self.executePhase(\"phase_1\", series)\n",
    "        # phase 2\n",
    "        series = self.extractSeriesFromCryptoCompare(crypto_currency)\n",
    "        self.executePhase(\"phase_2\", series)\n",
    "        #phase 3\n",
    "        self.executeOnTimer(crypto_currency)\n",
    "\n",
    "    def executeOnTimer(self, crypto_currency):\n",
    "        print(\"execute On Timer\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time >= 30:\n",
    "                start_time = time.time()\n",
    "\n",
    "                try:\n",
    "                    if not os.path.exists('live_sol_rates.csv'):\n",
    "                        self.client.download_file('eoghancs6512', 'results/live_sol_rates.csv', os.path.join('/home/ec2-user/SageMaker/', 'live_sol_rates.csv'))\n",
    "                    series = pd.read_csv('live_sol_rates.csv')['offer'].tolist()\n",
    "                except botocore.exceptions.ClientError as e:\n",
    "                    series = []\n",
    "\n",
    "                reader = CryptoCompareReader()\n",
    "                live_rate = reader.readCurrentRate(crypto_currency)\n",
    "\n",
    "                with open('live_sol_rates.csv', 'a') as csvfile:\n",
    "                    if os.stat('live_sol_rates.csv').st_size == 0:\n",
    "                        csvfile.write(\"offer\\n\")\n",
    "                    csvfile.write(f\"{live_rate}\\n\")\n",
    "                print(f\"Live rate is {live_rate}\")\n",
    "                if len(series) >= 100:\n",
    "                    rates_csv = pd.read_csv('live_sol_rates.csv')['offer']\n",
    "                    self.saveCsvToBucket(pd.Series(rates_csv), 'live_sol_rates.csv')\n",
    "                    series = pd.Series(series)\n",
    "                    self.executePhase(\"phase_3\", series)\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"live rates: {len(series)}/100\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071d189",
   "metadata": {},
   "source": [
    "## Bucket Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c66a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in phase_1\n",
      "Getting sample that has outliers for all methods\n",
      "{'series': [92.865, 167.49, 190.47, 96.95, 171.19, 86.53, 139.52, 95.4, 115.185, 179.64, 148.48, 151.62, 138.025, 139.98, 137.14, 110.96, 96.77, 96.11, 172.87, 99.78, 150.46, 170.49, 164.2, 113.83, 135.42, 182.475, 196.38, 140.81, 140.26, 137.06, 170.88, 143.67, 93.42, 141.41, 146.83, 153.41, 195.95, 110.65, 180.17, 172.37, 178.225, 101.16, 134.78, 171.44, 166.68, 136.095, 163.97, 101.97, 109.67, 149.54, 174.32, 151.35, 138.86, 89.775, 117.95, 187.855, 119.365, 105.63, 142.765, 113.795, 96.76, 202.335, 92.85, 93.4, 181.67, 181.88, 179.33, 92.9, 139.28, 162.41, 150.79, 119.36, 226.79, 140.38, 175.75, 94.215, 111.46, 91.975, 125.525, 179.96, 140.28, 110.31, 182.675, 176.315, 178.6, 171.97, 161.06, 168.66, 110.82, 102.46, 138.86, 170.91, 192.975, 139.57, 107.8, 103.12, 118.18, 193.03, 97.04, 105.47], 'outliers': {'joint_outliers': [190.47, 86.53, 115.185, 99.78, 135.42, 196.38, 146.83, 153.41, 195.95, 101.16, 134.78, 89.775, 117.95, 187.855, 119.365, 202.335, 119.36, 226.79, 91.975, 125.525, 161.06, 192.975, 107.8, 118.18, 193.03], 'DixonQ': [92.865, 167.49, 190.47, 96.95, 171.19, 86.53, 139.52, 95.4, 115.185, 179.64, 148.48, 151.62, 138.025, 139.98, 137.14, 110.96, 172.87, 99.78, 150.46, 170.49, 164.2, 113.83, 135.42, 182.475, 196.38, 137.06, 170.88, 143.67, 93.42, 141.41, 146.83, 153.41, 195.95, 110.65, 180.17, 172.37, 178.225, 101.16, 134.78, 171.44, 166.68, 136.095, 163.97, 101.97, 109.67, 149.54, 174.32, 151.35, 138.86, 89.775, 117.95, 187.855, 119.365, 105.63, 142.765, 113.795, 96.76, 202.335, 179.33, 92.9, 139.28, 162.41, 150.79, 119.36, 226.79, 140.38, 175.75, 94.215, 111.46, 91.975, 125.525, 179.96, 140.28, 110.31, 182.675, 176.315, 178.6, 171.97, 161.06, 168.66, 110.82, 102.46, 170.91, 192.975, 139.57, 107.8, 103.12, 118.18, 193.03, 97.04, 105.47], 'StandardDeviation': [226.79], 'IsolationForest': [86.53, 89.775, 91.975, 99.78, 101.16, 107.8, 115.185, 117.95, 118.18, 119.36, 119.365, 125.525, 134.78, 135.42, 146.83, 153.41, 161.06, 187.855, 190.47, 192.975, 193.03, 195.95, 196.38, 202.335, 226.79], 'Boxplot': [], 'DBSCAN': [86.53, 89.775, 91.975, 92.85, 92.865, 92.9, 93.4, 93.42, 94.215, 95.4, 96.11, 96.76, 96.77, 96.95, 97.04, 99.78, 101.16, 101.97, 102.46, 103.12, 105.47, 105.63, 107.8, 109.67, 110.31, 110.65, 110.82, 110.96, 111.46, 113.795, 113.83, 115.185, 117.95, 118.18, 119.36, 119.365, 125.525, 134.78, 135.42, 136.095, 137.06, 137.14, 138.025, 141.41, 142.765, 143.67, 146.83, 148.48, 149.54, 150.46, 150.79, 151.35, 151.62, 153.41, 161.06, 162.41, 163.97, 164.2, 166.68, 167.49, 168.66, 170.49, 170.88, 170.91, 171.19, 171.44, 171.97, 172.37, 172.87, 174.32, 175.75, 176.315, 178.225, 178.6, 179.33, 179.64, 179.96, 180.17, 181.67, 181.88, 182.475, 182.675, 187.855, 190.47, 192.975, 193.03, 195.95, 196.38, 202.335, 226.79], 'Joint_Outliers_DQ_StD': [226.79], 'Joint_Outliers_DQ_IF': [134.78, 135.42, 146.83, 153.41, 161.06, 187.855, 190.47, 192.975, 193.03, 195.95, 196.38, 202.335, 86.53, 119.36, 89.775, 91.975, 226.79, 99.78, 101.16, 107.8, 115.185, 117.95, 118.18, 119.365, 125.525], 'Joint_Outliers_StD_IF': [226.79]}}\n",
      "in phase_2\n",
      "Getting sample that has outliers for all methods\n",
      "{'series': [180.02, 127.65, 30.59, 40.55, 35.37, 33.74, 62.11, 88.07, 43.54, 30.69, 24.36, 22.26, 20.46, 202.3, 21.99, 101.77, 50.25, 9.909, 12.37, 95.71, 23.92, 182.92, 13.43, 41.87, 30.79, 199.72, 94.65, 36.48, 181.41, 52.12, 23.93, 81.26, 20.96, 24.35, 93.58, 36.6, 40.56, 58.74, 13.98, 91.31, 176.92, 24.68, 75.31, 23.97, 36.27, 21.43, 221.94, 112.99, 89.93, 238.17, 81.65, 11.81, 38.46, 197.89, 35.42, 37.01, 179.76, 13.82, 30.43, 93.32, 22.38, 9.641, 229.91, 173.06, 24.57, 38.05, 35.28, 136.39, 200.92, 38.62, 33.86, 78.76, 14.15, 13.69, 102.1, 32.62, 37.37, 34.69, 31.6, 134.54, 22.2, 35.01, 20.69, 39.93, 170.62, 23.01, 37.46, 49.37, 184.52, 111.02, 32.2, 33.74, 21.18, 31.95, 19.3, 142.11, 22.7, 38.97, 85.84, 89.68], 'outliers': {'joint_outliers': [229.91, 238.17, 199.72, 200.92, 202.3, 221.94], 'DixonQ': [], 'StandardDeviation': [229.91, 238.17], 'IsolationForest': [9.641, 9.909, 11.81, 12.37, 13.43, 13.69, 14.15, 19.3, 43.54, 49.37, 50.25, 52.12, 58.74, 62.11, 75.31, 78.76, 101.77, 102.1, 111.02, 112.99, 127.65, 134.54, 136.39, 142.11, 170.62, 173.06, 176.92, 179.76, 180.02, 181.41, 182.92, 184.52, 197.89, 199.72, 200.92, 202.3, 221.94, 229.91, 238.17], 'Boxplot': [199.72, 200.92, 202.3, 221.94, 229.91, 238.17], 'DBSCAN': [9.641, 9.909, 11.81, 12.37, 19.3, 30.43, 30.59, 30.69, 30.79, 31.6, 31.95, 32.2, 32.62, 33.74, 33.74, 33.86, 36.27, 36.48, 36.6, 37.01, 37.37, 37.46, 38.05, 38.46, 38.62, 38.97, 39.93, 40.55, 40.56, 41.87, 43.54, 49.37, 50.25, 52.12, 58.74, 62.11, 75.31, 78.76, 81.26, 81.65, 85.84, 88.07, 89.68, 89.93, 91.31, 93.32, 93.58, 94.65, 95.71, 101.77, 102.1, 111.02, 112.99, 127.65, 134.54, 136.39, 142.11, 170.62, 173.06, 176.92, 179.76, 180.02, 181.41, 182.92, 184.52, 197.89, 199.72, 200.92, 202.3, 221.94, 229.91, 238.17], 'Joint_Outliers_DQ_StD': [], 'Joint_Outliers_DQ_IF': [], 'Joint_Outliers_StD_IF': [229.91, 238.17]}}\n",
      "execute On Timer\n",
      "Live rate is 20.98\n",
      "in phase_3\n",
      "Getting sample that has outliers for all methods\n",
      "{'series': [21.18, 21.14, 21.19, 21.15, 21.17, 21.15, 21.2, 21.13, 21.2, 21.15, 21.13, 21.19, 21.12, 21.22, 21.14, 21.17, 21.13, 21.15, 21.22, 21.21, 21.21, 21.21, 21.16, 21.15, 21.14, 21.17, 21.12, 21.21, 21.19, 21.22, 21.14, 21.16, 21.13, 21.16, 21.17, 21.21, 21.22, 21.15, 21.18, 21.13, 21.13, 21.13, 21.17, 21.21, 21.21, 21.15, 21.19, 21.13, 21.02, 21.23, 21.21, 21.18, 21.16, 21.15, 21.02, 21.2, 21.17, 21.13, 21.22, 21.16, 21.22, 21.12, 21.17, 21.21, 21.13, 21.24, 21.19, 21.19, 21.19, 21.17, 21.15, 21.15, 21.17, 21.15, 21.17, 21.14, 21.2, 21.14, 21.14, 21.15, 21.2, 21.17, 21.18, 21.21, 21.17, 17.918, 21.16, 21.19, 21.23, 21.15, 21.22, 21.13, 21.21, 21.21, 21.13, 21.16, 21.17, 21.16, 21.19, 21.18], 'outliers': {'joint_outliers': [17.918, 21.02, 21.12], 'DixonQ': [], 'StandardDeviation': [17.918], 'IsolationForest': [17.918, 21.02, 21.02, 21.12, 21.12, 21.12, 21.23, 21.23, 21.24], 'Boxplot': [17.918, 21.02, 21.02], 'DBSCAN': [17.918], 'Joint_Outliers_DQ_StD': [], 'Joint_Outliers_DQ_IF': [], 'Joint_Outliers_StD_IF': [17.918]}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "def main():\n",
    "    # Set up the S3 client\n",
    "    bucket_name = 'eoghancs6512'\n",
    "    file_name = \"instrument_price.csv\"\n",
    "    crypto_currency = \"SOL\"\n",
    "    object_name = 'data/' + file_name\n",
    "\n",
    "    # Create local data directory to copy data folder from s3 bucket.\n",
    "    local_dir_path = '/home/ec2-user/SageMaker/data'\n",
    "\n",
    "    # Create the local directory if it doesn't already exist\n",
    "    if not os.path.exists(local_dir_path):\n",
    "        os.makedirs(local_dir_path)\n",
    "\n",
    "    # Copying data directory from s3 to local data folder\n",
    "    s3.download_file(bucket_name, object_name, os.path.join(local_dir_path, 'instrument_price.csv'))\n",
    "\n",
    "    assignment = bucket_class(bucket_name)\n",
    "    assignment.execute(file_name, crypto_currency)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
